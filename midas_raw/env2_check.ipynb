{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Env_c import Env\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    done = False\n",
    "    env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        print(\"Action: \", action, \"Reward\", reward, \"Done\", done, \"Distance Rate\", env.distance_rate, \"Heading\", env.heading)\n",
    "\n",
    "        # print(\"State: \", n_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/midas\"\n",
    "logdir = \"logs\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):  \n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(True)\n",
    "# env = Monitor(env, filename=\"log.txt\" ,info_keywords=(\"collide\", \"goal\", 'limit'))\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'models/midas/midas_50000_steps'\n",
    "model = TD3.load(path, env=env)\n",
    "# model = TD3(\"MlpPolicy\", env, seed=0, verbose=1, tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(save_freq=1000, save_path=models_dir,\n",
    "                                         name_prefix='midas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=300_000, reset_num_timesteps=False, tb_log_name=\"midas\", callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(True)\n",
    "env = Monitor(env, filename=\"log.txt\" ,info_keywords=(\"collide\", \"goal\", 'limit'))\n",
    "\n",
    "env.reset()\n",
    "# PPO_path = 'models/TD3/TD3_model_375000_steps'\n",
    "# model = TD3.load(PPO_path, env=env)\n",
    "model = TD3(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(False)\n",
    "PPO_path = 'models/TD3/TD3_model_375000_steps'\n",
    "model = TD3.load(PPO_path, env=env)\n",
    "# model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_reward = 0\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    # time.sleep(10)\n",
    "\n",
    "    \n",
    "    while not done:\n",
    "        # action, _ = model.predict(obs, deterministic=True)\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        t_reward += reward\n",
    "        # print(\"Action: \", action, \"Reward\", reward, \"Done\", done, \"Distance Rate\", env.distance_rate*500, \"Heading\", env.heading)\n",
    "        # print(\"Distance Rate\", env.distance_rate*1, \"Current Distance\", env.current_distance, \"Heading\", env.heading)\n",
    "        print(action)\n",
    "        # print(\"State: \", n_state)\n",
    "\n",
    "print(t_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    obs, reward, done, info = env.step(3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad0e1e0751e4cc160a6a642e24774d488557f676fee55568e2a63715f0f65130"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('py37-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
